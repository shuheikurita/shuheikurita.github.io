---
permalink: /
title: "<span style='color: #333333;'>Shuhei Kurita</span>"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---
<span style='color: #333333;'>(ja: 栗田修平)</span>
<!--# Shuhei Kurita ( ja: 栗田修平 )-->

## <span style='color: navy;'>Bio</span>
Dr. Shuhei Kurita is an Assistant Professor at National Institute of Informatics and a Specially Appointed Associate Professor at Institute of Science Tokyo.<br/>
He obtained his PhD of Informatics from Kyoto University in 2019. His research interests include language modelings and visual foundation modelings, including vision, language and action modelings. He has a keen interest in developing language models with real world understandings and application to computer vision and robotics.<br>

<p>
Contact: 
skurita at nii.ac.jp<br>
<i>My old email of shuhei.kurita at riken.jp <em>expired</em> at the end of March 2025.</i>
<!--<img src="contact.png" alt="contact.png" title="contact" width="30%" height="30%">-->
</p>

## <span style='color: #cc0033;'>Call for students</span>
Our lab accepts new students in the informatics course of SOKENDAI. [See this](/students/)<br>
総研大情報学コースで学生を受けいれております。[こちらをお読みください](/students/)

## <span style='color: green;'>News</span>

### 1, February, 2026
Our paper is accepted to ICRA2026!</br>
Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori, 
“Developing Vision-Language-Action Model from Egocentric Videos”,
ICRA2026.
[\[arXiv\]](https://www.arxiv.org/abs/2509.21986)

### 27, September, 2025
Our paper is accepted to ACMMM2025!</br>
Mahiro Ukai, Shuhei Kurita, Nakamasa Inoue, 
"STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models",
ACMMM2025.
[\[paper\]](https://dl.acm.org/doi/10.1145/3746027.3755565)

### 26, June, 2025
Three papers are accepted to ICCV2025!</br>
Kanoko Goto, Takumi Hirose, Mahiro Ukai, Shuhei Kurita, Nakamasa Inoue,
“Referring Expression Comprehension for Small Objects”,
[\[paper\]](https://openaccess.thecvf.com/content/ICCV2025/papers/Goto_Referring_Expression_Comprehension_for_Small_Objects_ICCV_2025_paper.pdf).</br>
Jungdae Lee, Taiki Miyanishi, Shuhei Kurita, Koya Sakamoto, Daichi Azuma, Yutaka Matsuo and Nakamasa Inoue,
“CityNav: A Large-Scale Dataset for Real-World Aerial Navigation”,
[\[paper\]](https://openaccess.thecvf.com/content/ICCV2025/papers/Lee_CityNav_A_Large-Scale_Dataset_for_Real-World_Aerial_Navigation_ICCV_2025_paper.pdf).</br>
Shunsuke Yasuki, Taiki Miyanishi, Nakamasa Inoue, Shuhei Kurita, Koya Sakamoto, Daichi Azuma, Masato Taki, Yutaka Matsuo,
“GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields”,
[\[paper\]](https://openaccess.thecvf.com/content/ICCV2025/papers/Yasuki_GeoProg3D_Compositional_Visual_Reasoning_for_City-Scale_3D_Language_Fields_ICCV_2025_paper.pdf).</br>

### 17, June, 2025
Our paper is accepted to IROS2025!<br/>
Yuta Irisawa, Tomoaki Yamazaki, Seiya Ito, Shuhei Kurita, Ryota Akasaka, Masaki Onishi, Kouzou Ohara, Ken Sakurada, “Low-Latency Privacy-Aware Robot Behavior guided by Automatically Generated Text Datasets”, IROS2025.
[\[paper\]](https://ieeexplore.ieee.org/document/11246252).</br>

### 8, March, 2025
Our paper is accepted to CVPR2025!</br>
Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori,
"Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision",
CVPR2025.
[\[project\]](https://biscue5.github.io/egoscaler-project-page/)[\[arXiv\]](https://arxiv.org/abs/2506.03605)

### 23, January, 2025
Two papers are accepted to NAACL2025!</br>
Eri Onami, Taiki Miyanishi, Koki Maeda, Shuhei Kurita, “LegalViz: Legal Text Visualization by Text To Diagram Generation”,
[\[paper\]](https://aclanthology.org/2025.naacl-long.339/).</br>
Keito Sasagawa, Koki Maeda, Issa Sugiura, Shuhei Kurita, Naoaki Okazaki, Daisuke Kawahara, “Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model”,
[\[paper\]](https://aclanthology.org/2025.naacl-demo.38/).</br>

### 30, June, 2024
Two papers are accepted to IROS2024!<br/>
Daichi Azuma, Taiki Miyanishi, Shuhei Kurita, Koya Sakamoto and Motoaki Kawanabe Answerability Fields: Answerable Location Estimation via Diffusion Models, IROS 2024.<br/>
Koya Sakamoto, Daichi Azuma, Taiki Miyanishi, Shuhei Kurita and Motoaki Kawanabe, Map-based Modular Approach for Zero-shot Embodied Question Answering, IROS 2024.<br/>

### 21, Feb., 2024
Two papers are accepted to LREC-COLING2024!<br/>
Eri Onami, Shuhei Kurita, Taiki Miyanishi, Taro Watanabe,
JDocQA: Japanese Document Question Answering Dataset for Generative Language Models<br/>
Chieko Nishimura, Shuhei Kurita and Yohei Seki,
Text360Nav: 360-Degree Image Captioning Dataset for Urban Pedestrians Navigation<br/>

### 8, Oct., 2023
Two papers are accepted to EMNLP2023 findings!<br/>
Koki Maeda, Shuhei Kurita, Taiki Miyanishi, Naoaki Okazaki,<br/>
Query-based Image Captioning from Multi-context 360° Images<br/>
Shunya Kato, Shuhei Kurita, Chenhui Chu, Sadao Kurohashi,<br/>
ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes<br/>

### 22, Seq., 2023
Our paper is accepted to NeurIPS2023 Datasets and Benchmarks track!<br/>
Taiki Miyanishi, Fumiya Kitamori, Shuhei Kurita, Jungdae Lee, Motoaki Kawanabe, Nakamasa Inoue,<br/>
CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale Point Cloud Data<br/>

### 20, July, 2023
Our paper is accepted to ICCV2023!<br/>
RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D<br/>
Shuhei Kurita, Naoki Katsura and Eri Onami<br/>
Update: [\[arXiv paper\]](https://arxiv.org/abs/2308.12035) [\[code\]](https://github.com/shuheikurita/RefEgo) available!

### 1, April, 2023
I become a research scientist in the RIKEN-AIP LIAT team, Japan.

### 1, Feb., 2023
We will obtain JSPS Fund for the Promotion of Joint International Research (Fostering Joint International Research(A)) （科研費 国際共同研究強化（Ａ））from Japan, starting from April, 2023!

### 10, Oct., 2022
We will make the follwing two presentations at COLING2022 conference!<br/>
- <u>Shuhei Kurita</u>, Hiroki Ouchi, Kentaro Inui and Satoshi Sekine
Iterative Span Selection: Self-Emergence of Resolving Orders in Semantic Role Labeling.
- Keisuke Shirai, Atsushi Hashimoto, Taichi Nishimura, Hirotaka Kameko, <u>Shuhei Kurita</u>, Yoshitaka Ushiku and Shinsuke Mori
Visual Recipe Flow: A Dataset for Learning Visual State Changes of Objects with Recipe Flows.

Thank you to my co-authors!!

### 2, Mar., 2022
Our paper is accepted to CVPR2022!<br/>
**ScanQA: 3D Question Answering for Spatial Scene Understanding**<br/>
Daichi Azuma(\*), Taiki Miyanishi(\*), <u>Shuhei Kurita</u>(\*), Motoaki Kawanabe.<br/>
(\*): equally contributed<br>
Thank you to my co-authors!!

### 1, Mar., 2022
My research grant proporal for JSPS Grant-in-Aid for Young Scientists in Japan is acceped!

### 26, Aug., 2021
Our paper is accepted to EMNLP2021 Findings!<br/>
**Co-Teaching Student-Model through Submission Results of Shared Task**<br/>
Kouta Nakayama, <u>Shuhei Kurita</u>, Akio Kobayashi, Yukino Baba and Satoshi Sekine.<br/>

### 12, Jan., 2021
Our paper at NYU visiting with Prof. Kyunghyun Cho is accepted to ICLR2021!<br/>
Shuhei Kurita and Kyunghyun Cho<br/>
**Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes’ Rule**. [OpenReview](https://openreview.net/forum?id=45uOPa46Kh) 

### 24, Nov., 2020
I am selected as a JST PRESTO "Trustworthy AI" reseach project member from December! <br/>
(~3.5 years, ~40M yens.)<br/>
I will delightedly work with many researchers in and out of PRESTO!

### 9, Jan., 2020
Thank you for Prof. Kyunghyun Cho and many NYU people, I start my co-working with Cho at NYU from this January. If you are at NYU or NY, I'm so happy to work with you. Feel free to reach me!

### 2, Oct., 2019
Our paper "**Reconstructing neuronal circuitry from parallel spike trains**" has been published from Nature Communications!
Ryota Kobayashi, Shuhei Kurita, Anno Kurth, Katsunori Kitano, Kenji Mizuseki, Markus Diesmann, Barry J. Richmond & Shigeru Shinomoto.<br/>
[https://www.nature.com/articles/s41467-019-12225-2](https://www.nature.com/articles/s41467-019-12225-2)

### 14, May, 2019
Our paper "Multi-Task Semantic Dependency Parsing with Policy Gradient for Learning Easy-First Strategies," (Long)  has been accepted to ACL2019!<br/>
[https://www.aclweb.org/anthology/P19-1232/](https://www.aclweb.org/anthology/P19-1232/)

### 1, April, 2019
I received Ph.D. of Informatics from Kyoto University on March 25, 2019!
Now I join the Center for Advanced Intelligence Project, RIKEN, Nihombashi, Tokyo with Prof. Satoshi Sekine.
I am adapted to JST ACT-I Research Projects Acceleration Phase (2019.4-2021.3).

## Publications
[Publications](/publications/) <br/>

## CV
[CV](/cv/) <br/>

